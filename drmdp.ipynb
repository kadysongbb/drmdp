{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 MIP Bellman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 DRMDP with decision dependent ambiguity set (DRMDP DD1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "def solve_bellman_formulation1(act_dim, num_states, lam, next_V, k, delta_s, rho_s, delta_0_s, rho_0_s, ub_a):\n",
    "    model2 = gp.Model()\n",
    "    model2.setParam('OutputFlag', False)\n",
    "    a = [0 for i in range(act_dim)]\n",
    "    w = [0 for i in range(num_states)]\n",
    "    u = [0 for i in range(num_states)]\n",
    "    m0 = [[0 for j in range(num_states)] for i in range(act_dim)]\n",
    "    m1 = [[0 for j in range(num_states)] for i in range(act_dim)]\n",
    "    r = model2.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'r')\n",
    "    q = model2.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'q')\n",
    "    for i in range(act_dim):\n",
    "        a[i] = model2.addVar(vtype=GRB.INTEGER, lb = 0.0, ub = ub_a[i], name = 'a%d' %i)\n",
    "    for i in range(num_states):\n",
    "        w[i] = model2.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'w%d' %i)\n",
    "    for i in range(num_states):\n",
    "        u[i] = model2.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'u%d' %i)\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            m0[i][j] = model2.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm0-%d%d' %(i,j))\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "                m1[i][j] = model2.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm1-%d%d' %(i,j))\n",
    "\n",
    "    # Objective\n",
    "    obj = 1*r + delta_0_s\n",
    "    for i in range(act_dim):\n",
    "        obj.addTerms(delta_s[i], a[i])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(-rho_0_s[j], w[j])\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            obj.addTerms(-rho_s[i][j], m0[i][j])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(rho_0_s[j], u[j])\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            obj.addTerms(rho_s[i][j], m1[i][j])\n",
    "    model2.setObjective(obj, GRB.MAXIMIZE)   \n",
    "\n",
    "    # Constraint 1\n",
    "    model2.addConstr(q-r, GRB.GREATER_EQUAL, 0, \"c1\");\n",
    "\n",
    "    # Constraint 2\n",
    "    for j in range(num_states):\n",
    "        model2.addConstr(lam*next_V[j] + w[j] - u[j] - q >= 0)\n",
    "    \n",
    "    # McCormick envelopes\n",
    "    # M0\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            model2.addConstr(m0[i][j] - 0*w[j] - a[i]*0 + 0*0 >= 0, \"m0-1-%d%d\" %(i,j))\n",
    "            model2.addConstr(m0[i][j] - ub_a[i]*w[j] - a[i]*k[j] + ub_a[i]*k[j] >= 0, \"m0-2-%d%d\" %(i,j))\n",
    "            model2.addConstr(m0[i][j] - ub_a[i]*w[j] - a[i]*0 + ub_a[i]*0 <= 0, \"m0-3-%d%d\" %(i,j))\n",
    "            model2.addConstr(m0[i][j] - a[i]*k[j] - 0*w[j] + 0*k[j] <= 0, \"m0-4-%d%d\" %(i,j))\n",
    "    \n",
    "    # M1\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            model2.addConstr(m1[i][j] - 0*u[j] - a[i]*0 + 0*0 >= 0, \"m1-1-%d%d\" %(i,j))\n",
    "            model2.addConstr(m1[i][j] - ub_a[i]*u[j] - a[i]*k[j] + ub_a[i]*k[j] >= 0, \"m1-2-%d%d\" %(i,j))\n",
    "            model2.addConstr(m1[i][j] - ub_a[i]*u[j] - a[i]*0 + ub_a[i]*0 <= 0, \"m1-3-%d%d\" %(i,j))\n",
    "            model2.addConstr(m1[i][j] - a[i]*k[j] - 0*u[j] + 0*k[j] <= 0, \"m1-4-%d%d\" %(i,j))\n",
    "\n",
    "    result = model2.optimize()\n",
    "    a = []\n",
    "    for v in model2.getVars():\n",
    "        # print('%s %g,' % (v.varName, v.x), end = \" \")\n",
    "        if 'a' in v.varName:\n",
    "            a.append(v.x)\n",
    "    optimal_objective = model2.getObjective().getValue()\n",
    "    optimal_a = np.asarray(a)\n",
    "    return optimal_objective, optimal_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 DRMDP with decision dependent ambiguity set (DRMDP DD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "def solve_bellman_formulation2(act_dim, num_states, lam, next_V, k, K, delta_s, rho_s, sigma_s,\n",
    "                                            delta_0_s, rho_0_s, sigma_0_s, bar_Sigma_s, ub_a):\n",
    "    model1 = gp.Model()\n",
    "    model1.setParam('OutputFlag', False)\n",
    "    a = [0 for i in range(act_dim)]\n",
    "    w = [0 for i in range(num_states)]\n",
    "    u = [0 for i in range(num_states)]\n",
    "    Q = [[0 for j in range(num_states)] for i in range(num_states)]\n",
    "    h = [0 for i in range(num_states)]\n",
    "    m0 = [[0 for j in range(num_states)] for i in range(act_dim)]\n",
    "    m1 = [[0 for j in range(num_states)] for i in range(act_dim)]\n",
    "    m2 = [[[0 for j_ in range(num_states)] for j in range(num_states)] for i in range(act_dim)]\n",
    "    m3 = [[[[0 for j_ in  range(num_states)] for j in range(num_states)] for i_ in range(act_dim)] for i in range(act_dim)]\n",
    "    m4 = [[0 for j in range(num_states)] for i in range(num_states)]\n",
    "    m5 = [[0 for j in range(num_states)] for i in range(num_states)]\n",
    "\n",
    "\n",
    "    r = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'r')\n",
    "    q = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'q')\n",
    "    for i in range(act_dim):\n",
    "        a[i] = model1.addVar(vtype=GRB.INTEGER, lb = 0.0, ub = ub_a[i], name = 'a%d' %i)\n",
    "    for i in range(num_states):\n",
    "        w[i] = model1.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'w%d' %i)\n",
    "    for i in range(num_states):\n",
    "        u[i] = model1.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'u%d' %i)\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            Q[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -np.sqrt(K[i][i]*K[j][j]), ub = np.sqrt(K[i][i]*K[j][j]), name = 'Q%d%d' %(i,j))\n",
    "    for i in range(num_states):\n",
    "        h[i] = model1.addVar(vtype=GRB.CONTINUOUS, name = 'h%d' %i)\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            m0[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm0-%d%d' %(i,j))\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            m1[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm1-%d%d' %(i,j))\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            for j_ in range(num_states):\n",
    "                m2[i][j][j_] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm2-%d%d%d' %(i,j,j_))\n",
    "    for i in range(act_dim):\n",
    "        for i_ in range(act_dim):\n",
    "            for j in range(num_states):\n",
    "                for j_ in range(num_states):\n",
    "                    m3[i][i_][j][j_] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm3-%d%d%d%d' %(i,i_,j,j_))\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            m4[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm4-%d%d' %(i,j))\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            m5[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm5-%d%d' %(i,j))\n",
    "    \n",
    "    # Objective\n",
    "    obj = 1*r + delta_0_s\n",
    "    for i in range(act_dim):\n",
    "        obj.addTerms(delta_s[i], a[i])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(-rho_0_s[j], w[j])\n",
    "    for j in range(num_states):\n",
    "        for i in range(act_dim):\n",
    "            obj.addTerms(-rho_s[i][j], m0[i][j])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(rho_0_s[j], u[j])\n",
    "    for j in range(num_states):\n",
    "        for i in range(act_dim):\n",
    "            obj.addTerms(rho_s[i][j], m1[i][j])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            obj.addTerms(rho_0_s[j]*rho_0_s[j_], Q[j][j_])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            for i in range(act_dim):\n",
    "                obj.addTerms(rho_0_s[j_]*rho_s[i][j] + rho_0_s[j]*rho_s[i][j_], m2[i][j][j_])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            for i in range(act_dim):\n",
    "                for i_ in range(act_dim):\n",
    "                    obj.addTerms(rho_s[i][j]*rho_s[i_][j_], m3[i][i_][j][j_])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            obj.addTerms(-bar_Sigma_s[j][j_]*sigma_0_s, Q[j][j_])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            for i in range(act_dim):\n",
    "                obj.addTerms(-bar_Sigma_s[j][j_]*sigma_s[i], m2[i][j][j_])\n",
    "    model1.setObjective(obj, GRB.MAXIMIZE)\n",
    "\n",
    "    # Constraint 1\n",
    "    constraint1 = q - r\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            constraint1.addTerms(-1,m5[i][j])\n",
    "    model1.addConstr(constraint1, GRB.GREATER_EQUAL, 0, \"c1\")\n",
    "\n",
    "    # Constraint 2 -- j constraints\n",
    "    for j in range(num_states):\n",
    "        constraint = lam*next_V[j] + w[j] - u[j] - q\n",
    "        for i in range(num_states): \n",
    "            constraint.addTerms(1, m4[i][j])\n",
    "        for j_ in range(num_states):\n",
    "            constraint.addTerms(-2*rho_0_s[j_], Q[j][j_])\n",
    "        for j_ in range(num_states):\n",
    "            for i in range(act_dim):\n",
    "                constraint.addTerms(-2*rho_s[i][j_], m2[i][j][j_])\n",
    "        model1.addConstr(constraint, GRB.GREATER_EQUAL, 0, \"c2-%d\" %j);\n",
    "\n",
    "    # PSD\n",
    "    for i in range(num_states):\n",
    "        model1.addConstr(Q[i][i] >= gp.quicksum(Q[i][j] for j in range(num_states)), 'PSD diagonal dominance')\n",
    "        model1.addConstr(Q[i][i] >= 0, \"PSD positive diagonal\")\n",
    "        \n",
    "    # McCormick envelopes\n",
    "    # M0\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            model1.addConstr(m0[i][j] - 0*w[j] - a[i]*0 + 0*0 >= 0, \"m0-1-%d%d\" %(i,j))\n",
    "            model1.addConstr(m0[i][j] - ub_a[i]*w[j] - a[i]*k[j] + ub_a[i]*k[j] >= 0, \"m0-2-%d%d\" %(i,j))\n",
    "            model1.addConstr(m0[i][j] - ub_a[i]*w[j] - a[i]*0 + ub_a[i]*0 <= 0, \"m0-3-%d%d\" %(i,j))\n",
    "            model1.addConstr(m0[i][j] - a[i]*k[j] - 0*w[j] + 0*k[j] <= 0, \"m0-4-%d%d\" %(i,j))\n",
    "    \n",
    "    # M1\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            model1.addConstr(m1[i][j] - 0*u[j] - a[i]*0 + 0*0 >= 0, \"m1-1-%d%d\" %(i,j))\n",
    "            model1.addConstr(m1[i][j] - ub_a[i]*u[j] - a[i]*k[j] + ub_a[i]*k[j] >= 0, \"m1-2-%d%d\" %(i,j))\n",
    "            model1.addConstr(m1[i][j] - ub_a[i]*u[j] - a[i]*0 + ub_a[i]*0 <= 0, \"m1-3-%d%d\" %(i,j))\n",
    "            model1.addConstr(m1[i][j] - a[i]*k[j] - 0*u[j] + 0*k[j] <= 0, \"m1-4-%d%d\" %(i,j))\n",
    "    # M2\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            for j_ in range(num_states):\n",
    "                model1.addConstr(m2[i][j][j_] - 0*Q[j][j_] - a[i]*(-np.sqrt(K[j][j]*K[j_][j_])) + 0*(-np.sqrt(K[j][j]*K[j_][j_])) >= 0, \"m2-1-%d%d%d\" %(i,j,j_))\n",
    "                model1.addConstr(m2[i][j][j_] - ub_a[i]*Q[j][j_] - a[i]*np.sqrt(K[j][j]*K[j_][j_]) + ub_a[i]*np.sqrt(K[j][j]*K[j_][j_]) >= 0, \"m2-2-%d%d%d\" %(i,j,j_))\n",
    "                model1.addConstr(m2[i][j][j_] - ub_a[i]*Q[j][j_] - a[i]*(-np.sqrt(K[j][j]*K[j_][j_])) + ub_a[i]*(-np.sqrt(K[j][j]*K[j_][j_])) <= 0, \"m2-3-%d%d%d\" %(i,j,j_))\n",
    "                model1.addConstr(m2[i][j][j_] - a[i]*np.sqrt(K[j][j]*K[j_][j_]) - 0*Q[j][j_] + 0*np.sqrt(K[j][j]*K[j_][j_]) <= 0, \"m2-4-%d%d%d\" %(i,j,j_))\n",
    "\n",
    "    # ub-m2 -- ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])\n",
    "    # lb-m2 -- -ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])\n",
    "\n",
    "    # M3\n",
    "    for i in range(act_dim):\n",
    "        for i_ in range(act_dim):\n",
    "            for j in range(num_states):\n",
    "                for j_ in range(num_states):\n",
    "                    model1.addConstr(m3[i][i_][j][j_] - 0*m2[i][j][j_] - a[i_]*(-ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) + 0*(-ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) >= 0)\n",
    "                    model1.addConstr(m3[i][i_][j][j_] - ub_a[i_]*m2[i][j][j_] - a[i_]*(ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) + ub_a[i_]*(ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) >= 0)\n",
    "                    model1.addConstr(m3[i][i_][j][j_] - ub_a[i_]*m2[i][j][j_] - a[i_]*(-ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) + ub_a[i_]*(-ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) <= 0)\n",
    "                    model1.addConstr(m3[i][i_][j][j_] - a[i_]*(ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) - 0*m2[i][j][j_] + 0*(ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) <= 0)\n",
    "\n",
    "\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            model1.addConstr(m4[i][j] <= 1)\n",
    "            model1.addConstr(m4[i][j] >= -1)\n",
    "            model1.addConstr(m5[i][j] <= 1)\n",
    "            model1.addConstr(m5[i][j] >= -1)\n",
    "        \n",
    "        \n",
    "\n",
    "    result = model1.optimize()\n",
    "    a = []\n",
    "    for v in model1.getVars():\n",
    "        # print('%s %g,' % (v.varName, v.x), end = \" \")\n",
    "        if 'a' in v.varName:\n",
    "            a.append(v.x)\n",
    "    optimal_objective = model1.getObjective().getValue()\n",
    "    optimal_a = np.asarray(a)\n",
    "    return optimal_objective, optimal_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Regular MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "def solve_bellman_formulation3(act_dim, num_states, lam, next_V, delta_s, rho_s, delta_0_s, rho_0_s, ub_a):\n",
    "    model3 = gp.Model()\n",
    "    model3.setParam('OutputFlag', False)\n",
    "    a = [0 for i in range(act_dim)]\n",
    "    for i in range(act_dim):\n",
    "        a[i] = model3.addVar(vtype=GRB.INTEGER, lb = 0.0, ub = ub_a[i], name = 'a%d' %i)\n",
    "    # Objective\n",
    "    obj = delta_0_s + gp.quicksum(delta_s[i]*a[i] for i in range(act_dim))\n",
    "    for j in range(num_states):\n",
    "        obj += lam*rho_0_s[j]*next_V[j]\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            obj.addTerms(lam*rho_s[i][j]*next_V[j], a[i])\n",
    "    model3.setObjective(obj, GRB.MAXIMIZE)\n",
    "    \n",
    "    result = model3.optimize()\n",
    "    a = []\n",
    "    for v in model3.getVars():\n",
    "        # print('%s %g,' % (v.varName, v.x), end = \" \")\n",
    "        if 'a' in v.varName:\n",
    "            a.append(v.x)\n",
    "    optimal_objective = model3.getObjective().getValue()\n",
    "    optimal_a = np.asarray(a)\n",
    "    return optimal_objective, optimal_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# population size\n",
    "N = 10\n",
    "M = 1\n",
    "\n",
    "act_dim = 2\n",
    "num_states = (N+1)**2\n",
    "lam = 0.9\n",
    "next_V = np.zeros(num_states)\n",
    "\n",
    "\n",
    "# pernalty coefficients\n",
    "k = np.ones(num_states) \n",
    "K = np.ones((num_states, num_states))\n",
    "\n",
    "# LDR coefficients\n",
    "delta_s = np.ones(act_dim)\n",
    "delta_0_s = 1\n",
    "sigma_s = np.ones(act_dim)\n",
    "sigma_0_s = 1\n",
    "rho_s = np.ones((act_dim, num_states))\n",
    "rho_0_s = np.ones(num_states)\n",
    "ps = np.ones(num_states)\n",
    "\n",
    "bar_Sigma_s = np.ones((num_states, num_states))\n",
    "\n",
    "# bound of actions\n",
    "ub_a = np.asarray([N,M])\n",
    "\n",
    "objective, a1 = solve_bellman_formulation1(act_dim, num_states, lam, next_V, k, delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "print(objective)\n",
    "print(a1)\n",
    "\n",
    "\n",
    "objective, a2 = solve_bellman_formulation2(act_dim, num_states, lam, next_V, k, K, delta_s, rho_s, sigma_s,\n",
    "                                            delta_0_s, rho_0_s, sigma_0_s, bar_Sigma_s, ub_a)\n",
    "print(objective)\n",
    "print(a2)\n",
    "\n",
    "objective, a3 = solve_bellman_formulation3(act_dim, num_states, lam, next_V, delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "print(objective)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Vaccine Model Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def get_phi(state, action, population_size, trans_reduc_types, tau, mu):\n",
    "    # tau: probability that a susceptible person becomes infected upon contact with an infectious individual \n",
    "    # mu: the rate of contacts (contacts occur according to a homogenous Poisson process, the rate of contacts)\n",
    "    # beta(t): probability that the next interaction of a random susceptible person is with an infectious person\n",
    "    # alpha(t): the fractional reduction in the infection transmission rate\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    yvt = action[0]\n",
    "    yTt = action[1]\n",
    "    beta_t = xit/N\n",
    "    alpha_t = yTt/(M+1)\n",
    "    phi_t = 1 - np.exp(-(1-alpha_t)*mu*beta_t*tau)\n",
    "    return phi_t\n",
    "    \n",
    "\n",
    "def get_tilde_pas(state, action, population_size, trans_reduc_types, discretize, discretized_N, tau, mu):\n",
    "    # given a state, an action, return estimate of P(*|a,s)\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    dicretize_level = np.int(N/discretized_N)\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    yvt = action[0]\n",
    "    yTt = action[1]\n",
    "    phi_t = get_phi(state, action, N, M, tau, mu)\n",
    "    if discretize == False:\n",
    "        pas_matrix = np.zeros((N+1, N+1))\n",
    "        for xs in range(N+1):\n",
    "            for xi in range(N+1):\n",
    "                if xs + xi == xst - yvt:\n",
    "                    pas_matrix[xs][xi] = stats.binom.pmf(xi, xst - yvt, phi_t)\n",
    "        pas = pas_matrix.flatten()\n",
    "    else:\n",
    "        pas_matrix = np.zeros((discretized_N+1, discretized_N+1))\n",
    "        for s0 in range(discretized_N+1):\n",
    "            for s1 in range(discretized_N+1):\n",
    "                if s0 + s1 == np.int((xst - yvt)/dicretize_level):\n",
    "                    pas_matrix[s0][s1] = stats.binom.pmf(s1*dicretize_level, xst - yvt, phi_t)\n",
    "        pas = pas_matrix.flatten()\n",
    "        pas = pas/np.sum(pas)\n",
    "    return pas\n",
    "        \n",
    "\n",
    "def get_tilde_ras(state, action, population_size, trans_reduc_types, \n",
    "               cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu):\n",
    "    # given a state, an action, return estimate of r(a,s)\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    yvt = action[0]\n",
    "    yTt = np.int(action[1])\n",
    "    phi_t = get_phi(state, action, N, M, tau, mu)\n",
    "    E_it = (xst - yvt)*phi_t\n",
    "    # cost of implementing transmission reducing method \n",
    "    c_T = np.arange(M+1)*cT_multiplier\n",
    "    # policy maker WTP for health  \n",
    "    lam = wtp\n",
    "    c = cost_per_infect\n",
    "    w = qaly_loss_per_infect\n",
    "    p = vaccine_price\n",
    "    r = -lam*w*E_it - c*E_it - c_T[yTt] - p*yvt\n",
    "    return r\n",
    "\n",
    "def get_bar_pas_coefficients(state, population_size, trans_reduc_types, discretize = False, discretized_N = 100, tau = 0.8, mu = 1, vaccine_limit = 100):\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    if discretize == False:\n",
    "        num_states = (N+1)**2\n",
    "    else:\n",
    "        num_states = (discretized_N+1)**2\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    num_actions = 4\n",
    "    ds_action = np.zeros((num_actions, 2))\n",
    "    ds_pas = np.zeros((num_actions, num_states))\n",
    "    i = 0\n",
    "    yv_bound = [0, np.min([vaccine_limit, xst])]\n",
    "    yT_bound = [0, M]\n",
    "    for yv in yv_bound:\n",
    "        for yT in yT_bound:\n",
    "            action = np.asarray([yv, yT])\n",
    "            ds_action[i,:] = action\n",
    "            ds_pas[i,:] = get_tilde_pas(state, action, N, M, discretize, discretized_N, tau, mu)\n",
    "            i += 1\n",
    "    reg = LinearRegression().fit(ds_action, ds_pas)\n",
    "    rho_0_s = reg.intercept_\n",
    "    rho_s = reg.coef_\n",
    "    return rho_0_s, np.transpose(rho_s)\n",
    "\n",
    "def get_bar_pas(action, population_size, act_dim, rho_0_s, rho_s, discretize = False, discretized_N = 100):\n",
    "    N = population_size\n",
    "    if discretize == False:\n",
    "        num_states = (N+1)**2\n",
    "    else:\n",
    "        num_states = (discretized_N+1)**2\n",
    "    pas = rho_0_s\n",
    "    for j in range(num_states):\n",
    "        for i in range(act_dim):\n",
    "            pas[j] += rho_s[i][j]*action[i]\n",
    "    return pas\n",
    "\n",
    "def get_far_from_bar_pas(action, population_size, act_dim, rho_0_s, rho_s, discretize = False, discretized_N = 100):\n",
    "    bar_pas = get_bar_pas(action, population_size, act_dim, rho_0_s, rho_s, discretize, discretized_N)\n",
    "    ind = np.argpartition(bar_pas, -10)[-10:]\n",
    "    largest_10_values = bar_pas[ind].copy()\n",
    "    np.random.shuffle(largest_10_values)\n",
    "    far_from_bar_pas = bar_pas.copy()\n",
    "    far_from_bar_pas[ind] = largest_10_values\n",
    "    return far_from_bar_pas\n",
    "\n",
    "def get_far2_from_bar_pas(action, population_size, act_dim, rho_0_s, rho_s, discretize = False, discretized_N = 100):\n",
    "    bar_pas = get_bar_pas(action, population_size, act_dim, rho_0_s, rho_s, discretize, discretized_N)\n",
    "    ind = np.argpartition(bar_pas, -2)[-2:]\n",
    "    largest_2_values = bar_pas[ind].copy()\n",
    "    largest_2_values_copy = largest_2_values.copy()\n",
    "    largest_2_values_copy[0] = largest_2_values[1]\n",
    "    largest_2_values_copy[1] = largest_2_values[0]\n",
    "    far2_from_bar_pas = bar_pas.copy()\n",
    "    far2_from_bar_pas[ind] = largest_2_values_copy\n",
    "    return far2_from_bar_pas\n",
    "    \n",
    "def get_ras_coefficients(state, population_size, trans_reduc_types, cT_multiplier = 2, wtp = 1, \n",
    "                     cost_per_infect = 1, qaly_loss_per_infect = 1, vaccine_price = 0.1, tau = 0.8, mu = 1, vaccine_limit = 100):\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    num_actions = 4\n",
    "    ds_action = np.zeros((num_actions, 2))\n",
    "    ds_reward = np.zeros(num_actions)\n",
    "    i = 0\n",
    "    yv_bound = [0, np.min([vaccine_limit, xst])]\n",
    "    yT_bound = [0, M]\n",
    "    for yv in yv_bound:\n",
    "        for yT in yT_bound:\n",
    "            action = np.asarray([yv, yT])\n",
    "            ds_action[i,:] = action\n",
    "            ds_reward[i] = get_tilde_ras(state, action, N, M, cT_multiplier, wtp, \n",
    "                                                cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu)\n",
    "            i += 1\n",
    "    reg = LinearRegression().fit(ds_action, ds_reward)\n",
    "    delta_0_s = reg.intercept_\n",
    "    delta_s = reg.coef_\n",
    "    return delta_0_s, delta_s\n",
    "\n",
    "def get_ras(action, delta_s, delta_0_s):\n",
    "    ras = delta_0_s\n",
    "    for i in range(len(action)):\n",
    "        ras += delta_s[i]*action[i]\n",
    "    return ras\n",
    "\n",
    "def get_max_tilde_ras(state, population_size, trans_reduc_types, cT_multiplier = 2, wtp = 1, \n",
    "                     cost_per_infect = 1, qaly_loss_per_infect = 1, vaccine_price = 0.1, tau = 0.8, mu = 1, vaccine_limit = 100):\n",
    "    # max_a {tilde_ras} for a given state\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    yv_limit = np.int(np.min([vaccine_limit, xst]))\n",
    "    num_actions = (yv_limit+1)*(M+1)\n",
    "    ds_action = np.zeros((num_actions, 2))\n",
    "    ds_reward = np.zeros(num_actions)\n",
    "    i = 0\n",
    "    for yv in range(yv_limit+1):\n",
    "        for yT in range(M+1):\n",
    "            action = np.asarray([yv, yT])\n",
    "            ds_action[i,:] = action\n",
    "            ds_reward[i] = get_tilde_ras(state, action, N, M, cT_multiplier, wtp, \n",
    "                                                cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu)\n",
    "            i += 1\n",
    "    max_ras = np.max(ds_reward)\n",
    "    max_idx = np.argmax(ds_reward)\n",
    "    return ds_action[max_idx], max_ras\n",
    "\n",
    "def get_max_ras(state, trans_reduc_types, delta_s, delta_0_s, vaccine_limit = 100):\n",
    "    # max_a {ras} for a given state\n",
    "    M = trans_reduc_types\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    yv_limit = np.int(np.min([vaccine_limit, xst]))\n",
    "    num_actions = (yv_limit+1)*(M+1)\n",
    "    ds_action = np.zeros((num_actions, 2))\n",
    "    ds_reward = np.zeros(num_actions)\n",
    "    i = 0 \n",
    "    for yv in range(yv_limit+1):\n",
    "        for yT in range(M+1):\n",
    "            action = np.asarray([yv, yT])\n",
    "            ds_action[i,:] = action\n",
    "            ds_reward[i] = get_ras(action, delta_s, delta_0_s)\n",
    "            i += 1\n",
    "    max_ras = np.max(ds_reward)\n",
    "    max_idx = np.argmax(ds_reward)\n",
    "    return ds_action[max_idx], max_ras\n",
    "\n",
    "def get_fast_max_ras(state, trans_reduc_types, delta_s, delta_0_s, vaccine_limit = 100):\n",
    "    M = trans_reduc_types\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    num_actions = 4\n",
    "    ds_action = np.zeros((num_actions, 2))\n",
    "    ds_reward = np.zeros(num_actions)\n",
    "    i = 0\n",
    "    yv_bound = [0, np.min([vaccine_limit, xst])]\n",
    "    yT_bound = [0, M]\n",
    "    for yv in yv_bound:\n",
    "        for yT in yT_bound:\n",
    "            action = np.asarray([yv, yT])\n",
    "            ds_action[i,:] = action\n",
    "            ds_reward[i] = get_ras(action, delta_s, delta_0_s)\n",
    "            i += 1\n",
    "    max_ras = np.max(ds_reward)\n",
    "    max_idx = np.argmax(ds_reward)\n",
    "    return ds_action[max_idx], max_ras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Large Scale Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "niter = 10\n",
    "T = 12 # time horizon\n",
    "N = 1000 # population size\n",
    "discretized_N = 100\n",
    "M = 5 # types of transmission-reducing interventions \n",
    "lam = 0.9\n",
    "discretize = True\n",
    "\n",
    "act_dim = 2\n",
    "if discretize == False:\n",
    "    num_states = (N+1)**2\n",
    "else:\n",
    "    discretize_level = np.int(N/discretized_N)\n",
    "    num_states = (discretized_N+1)**2\n",
    "\n",
    "# pernalty coefficients\n",
    "k = np.ones(num_states)*0.001\n",
    "K = np.ones((num_states, num_states))\n",
    "\n",
    "# define initial state\n",
    "xs_init = np.int(N*9/10)\n",
    "xi_init = N - xs_init\n",
    "s_init = np.asarray([xs_init, xi_init])\n",
    "\n",
    "# define reward parameters\n",
    "unit = 50000\n",
    "cT_multiplier = N/20 * unit \n",
    "wtp = 1 * unit\n",
    "cost_per_infect = 1 * unit\n",
    "qaly_loss_per_infect = 1 # QALY\n",
    "vaccine_price = 0.5 * unit\n",
    "\n",
    "# define pas paramters \n",
    "tau = 0.7\n",
    "mu = 5\n",
    "vaccine_limit = N/10\n",
    "\n",
    "# build heuristic funcion \n",
    "V0 = np.zeros(num_states)\n",
    "for s0 in range(discretized_N+1):\n",
    "    for s1 in range(discretized_N+1):\n",
    "        current_s_idx = s0*(discretized_N+1) + s1\n",
    "        xs = s0*discretize_level\n",
    "        xi = s1*discretize_level\n",
    "        s = np.asarray([xs,xi])\n",
    "        delta_0_s, delta_s = get_ras_coefficients(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu, vaccine_limit)\n",
    "        _, max_ras = get_fast_max_ras(s, M, delta_s, delta_0_s, vaccine_limit)\n",
    "        V0[current_s_idx] = max_ras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Transition probability = bar_pas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 DRMDP DD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "xs_table = np.zeros((niter, T))\n",
    "xi_table = np.zeros((niter, T))\n",
    "a1_table = np.zeros((niter, T-1))\n",
    "a2_table = np.zeros((niter, T-1))\n",
    "for t in range(T-1):\n",
    "    V[:,t] = V0\n",
    "episode_rewards = np.zeros(niter)\n",
    "for i in range(niter):\n",
    "    print('Episode %d begins' %i)\n",
    "    total_reward = 0 \n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        rho_0_s, rho_s = get_bar_pas_coefficients(s, N, M, discretize, discretized_N, tau, mu, vaccine_limit)\n",
    "        delta_0_s, delta_s = get_ras_coefficients(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu, vaccine_limit)\n",
    "        ub_a = np.asarray([np.min([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation1(act_dim, num_states, lam, V[:,t+1], k, delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        xs_table[i][t] = s[0]\n",
    "        xi_table[i][t] = s[1]\n",
    "        a1_table[i][t] = a[0]\n",
    "        a2_table[i][t] = a[1]\n",
    "        # update reward\n",
    "        total_reward += get_ras(a, delta_s, delta_0_s)\n",
    "        # sample next state \n",
    "        pas = get_bar_pas(a, N, act_dim, rho_0_s, rho_s, discretize, discretized_N)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            s0 = np.int(next_s_idx/(discretized_N + 1))\n",
    "            s1 = next_s_idx % (discretized_N + 1)\n",
    "            xs = s0*discretize_level\n",
    "            xi = s1*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    xs_table[i][T-1] = s[0]\n",
    "    xi_table[i][T-1] = s[1]\n",
    "    print('Reward', total_reward)\n",
    "    episode_rewards[i] = total_reward\n",
    "    print('Episode %d ends' %i)\n",
    "print('Episodes reward', episode_rewards)\n",
    "print('Average reward', np.mean(episode_rewards))\n",
    "print('-std', np.mean(episode_rewards) - 0.5*np.std(episode_rewards))\n",
    "print('+std', np.mean(episode_rewards) + 0.5*np.std(episode_rewards))\n",
    "print('XS: \\n', xs_table)\n",
    "print('XI: \\n', xi_table)\n",
    "print('A1: \\n', a1_table)\n",
    "print('A2: \\n', a2_table)\n",
    "print('Average xs', np.mean(xs_table, axis = 0))\n",
    "print('Average xi', np.mean(xi_table, axis = 0))\n",
    "print('Average a1', np.mean(a1_table, axis = 0))\n",
    "print('Average a2', np.mean(a2_table, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Regular MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "xs_table = np.zeros((niter, T))\n",
    "xi_table = np.zeros((niter, T))\n",
    "a1_table = np.zeros((niter, T-1))\n",
    "a2_table = np.zeros((niter, T-1))\n",
    "for t in range(T-1):\n",
    "    V[:,t] = V0\n",
    "episode_rewards = np.zeros(niter)\n",
    "for i in range(niter):\n",
    "    print('Episode %d begins' %i)\n",
    "    total_reward = 0 \n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        rho_0_s, rho_s = get_bar_pas_coefficients(s, N, M, discretize, discretized_N, tau, mu, vaccine_limit)\n",
    "        delta_0_s, delta_s = get_ras_coefficients(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu, vaccine_limit)\n",
    "        ub_a = np.asarray([np.min([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation3(act_dim, num_states, lam, V[:,t+1], delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        xs_table[i][t] = s[0]\n",
    "        xi_table[i][t] = s[1]\n",
    "        a1_table[i][t] = a[0]\n",
    "        a2_table[i][t] = a[1]\n",
    "        # update reward\n",
    "        total_reward += get_ras(a, delta_s, delta_0_s)\n",
    "        # sample next state \n",
    "        pas = get_bar_pas(a, N, act_dim, rho_0_s, rho_s, discretize, discretized_N)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            s0 = np.int(next_s_idx/(discretized_N + 1))\n",
    "            s1 = next_s_idx % (discretized_N + 1)\n",
    "            xs = s0*discretize_level\n",
    "            xi = s1*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    xs_table[i][T-1] = s[0]\n",
    "    xi_table[i][T-1] = s[1]\n",
    "    print('Reward', total_reward)\n",
    "    episode_rewards[i] = total_reward\n",
    "    print('Episode %d ends' %i)\n",
    "print('Episodes reward', episode_rewards)\n",
    "print('Average reward', np.mean(episode_rewards))\n",
    "print('-std', np.mean(episode_rewards) - 0.5*np.std(episode_rewards))\n",
    "print('+std', np.mean(episode_rewards) + 0.5*np.std(episode_rewards))\n",
    "print('XS: \\n', xs_table)\n",
    "print('XI: \\n', xi_table)\n",
    "print('A1: \\n', a1_table)\n",
    "print('A2: \\n', a2_table)\n",
    "print('Average xs', np.mean(xs_table, axis = 0))\n",
    "print('Average xi', np.mean(xi_table, axis = 0))\n",
    "print('Average a1', np.mean(a1_table, axis = 0))\n",
    "print('Average a2', np.mean(a2_table, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Transition probability far from bar_pas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 DRMDP DD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "xs_table = np.zeros((niter, T))\n",
    "xi_table = np.zeros((niter, T))\n",
    "a1_table = np.zeros((niter, T-1))\n",
    "a2_table = np.zeros((niter, T-1))\n",
    "for t in range(T-1):\n",
    "    V[:,t] = V0\n",
    "episode_rewards = np.zeros(niter)\n",
    "for i in range(niter):\n",
    "    print('Episode %d begins' %i)\n",
    "    total_reward = 0 \n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        rho_0_s, rho_s = get_bar_pas_coefficients(s, N, M, discretize, discretized_N, tau, mu, vaccine_limit)\n",
    "        delta_0_s, delta_s = get_ras_coefficients(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu, vaccine_limit)\n",
    "        ub_a = np.asarray([np.min([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation1(act_dim, num_states, lam, V[:,t+1], k, delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        xs_table[i][t] = s[0]\n",
    "        xi_table[i][t] = s[1]\n",
    "        a1_table[i][t] = a[0]\n",
    "        a2_table[i][t] = a[1]\n",
    "        # update reward\n",
    "        total_reward += get_ras(a, delta_s, delta_0_s)\n",
    "        # sample next state \n",
    "        pas = get_far2_from_bar_pas(a, N, act_dim, rho_0_s, rho_s, discretize, discretized_N)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            s0 = np.int(next_s_idx/(discretized_N + 1))\n",
    "            s1 = next_s_idx % (discretized_N + 1)\n",
    "            xs = s0*discretize_level\n",
    "            xi = s1*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    xs_table[i][T-1] = s[0]\n",
    "    xi_table[i][T-1] = s[1]\n",
    "    print('Reward', total_reward)\n",
    "    episode_rewards[i] = total_reward\n",
    "    print('Episode %d ends' %i)\n",
    "print('Episodes reward', episode_rewards)\n",
    "print('Average reward', np.mean(episode_rewards))\n",
    "print('-std', np.mean(episode_rewards) - 0.5*np.std(episode_rewards))\n",
    "print('+std', np.mean(episode_rewards) + 0.5*np.std(episode_rewards))\n",
    "print('XS: \\n', xs_table)\n",
    "print('XI: \\n', xi_table)\n",
    "print('A1: \\n', a1_table)\n",
    "print('A2: \\n', a2_table)\n",
    "print('Average xs', np.mean(xs_table, axis = 0))\n",
    "print('Average xi', np.mean(xi_table, axis = 0))\n",
    "print('Average a1', np.mean(a1_table, axis = 0))\n",
    "print('Average a2', np.mean(a2_table, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Regular MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "xs_table = np.zeros((niter, T))\n",
    "xi_table = np.zeros((niter, T))\n",
    "a1_table = np.zeros((niter, T-1))\n",
    "a2_table = np.zeros((niter, T-1))\n",
    "for t in range(T-1):\n",
    "    V[:,t] = V0\n",
    "episode_rewards = np.zeros(niter)\n",
    "for i in range(niter):\n",
    "    print('Episode %d begins' %i)\n",
    "    total_reward = 0 \n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        rho_0_s, rho_s = get_bar_pas_coefficients(s, N, M, discretize, discretized_N, tau, mu, vaccine_limit)\n",
    "        delta_0_s, delta_s = get_ras_coefficients(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu, vaccine_limit)\n",
    "        ub_a = np.asarray([np.min([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation3(act_dim, num_states, lam, V[:,t+1], delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        xs_table[i][t] = s[0]\n",
    "        xi_table[i][t] = s[1]\n",
    "        a1_table[i][t] = a[0]\n",
    "        a2_table[i][t] = a[1]\n",
    "        # update reward\n",
    "        total_reward += get_ras(a, delta_s, delta_0_s)\n",
    "        # sample next state \n",
    "        pas = get_far2_from_bar_pas(a, N, act_dim, rho_0_s, rho_s, discretize, discretized_N)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            s0 = np.int(next_s_idx/(discretized_N + 1))\n",
    "            s1 = next_s_idx % (discretized_N + 1)\n",
    "            xs = s0*discretize_level\n",
    "            xi = s1*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    xs_table[i][T-1] = s[0]\n",
    "    xi_table[i][T-1] = s[1]\n",
    "    print('Reward', total_reward)\n",
    "    episode_rewards[i] = total_reward\n",
    "    print('Episode %d ends' %i)\n",
    "print('Episodes reward', episode_rewards)\n",
    "print('Average reward', np.mean(episode_rewards))\n",
    "print('-std', np.mean(episode_rewards) - 0.5*np.std(episode_rewards))\n",
    "print('+std', np.mean(episode_rewards) + 0.5*np.std(episode_rewards))\n",
    "print('XS: \\n', xs_table)\n",
    "print('XI: \\n', xi_table)\n",
    "print('A1: \\n', a1_table)\n",
    "print('A2: \\n', a2_table)\n",
    "print('Average xs', np.mean(xs_table, axis = 0))\n",
    "print('Average xi', np.mean(xi_table, axis = 0))\n",
    "print('Average a1', np.mean(a1_table, axis = 0))\n",
    "print('Average a2', np.mean(a2_table, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Small Scale Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "niter = 5\n",
    "T = 12 # time horizon\n",
    "N = 200 # population size\n",
    "discretized_N = 8\n",
    "M = 5 # types of transmission-reducing interventions \n",
    "lam = 0.9\n",
    "discretize = True\n",
    "\n",
    "act_dim = 2\n",
    "if discretize == False:\n",
    "    num_states = (N+1)**2\n",
    "else:\n",
    "    discretize_level = np.int(N/discretized_N)\n",
    "    num_states = (discretized_N+1)**2\n",
    "\n",
    "# pernalty coefficients\n",
    "k = np.ones(num_states) \n",
    "K = np.ones((num_states, num_states))\n",
    "\n",
    "\n",
    "# define initial state\n",
    "xs_init = np.int(N*7/10)\n",
    "xi_init = N - xs_init\n",
    "s_init = np.asarray([xs_init, xi_init])\n",
    "\n",
    "# define reward parameters \n",
    "unit = 50000\n",
    "cT_multiplier = N/20 * unit\n",
    "wtp = 1 * unit\n",
    "cost_per_infect = 1 * unit \n",
    "qaly_loss_per_infect = 1\n",
    "vaccine_price = 0.5 * unit\n",
    "\n",
    "# define pas paramters \n",
    "tau = 0.7\n",
    "mu = 5\n",
    "\n",
    "vaccine_limit = N/10\n",
    "\n",
    "sigma_s = np.zeros(act_dim)\n",
    "sigma_0_s = 1\n",
    "bar_Sigma_s = np.ones((num_states, num_states))\n",
    "\n",
    "# build heuristic funcion \n",
    "V0 = np.zeros(num_states)\n",
    "for s0 in range(discretized_N+1):\n",
    "    for s1 in range(discretized_N+1):\n",
    "        current_s_idx = s0*(discretized_N+1) + s1\n",
    "        xs = s0*discretize_level\n",
    "        xi = s1*discretize_level\n",
    "        s = np.asarray([xs,xi])\n",
    "        delta_0_s, delta_s = get_ras_coefficients(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu, vaccine_limit)\n",
    "        _, max_ras = get_fast_max_ras(s, M, delta_s, delta_0_s, vaccine_limit)\n",
    "        V0[current_s_idx] = max_ras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 DRMDP DD1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "xs_table = np.zeros((niter, T))\n",
    "xi_table = np.zeros((niter, T))\n",
    "a1_table = np.zeros((niter, T-1))\n",
    "a2_table = np.zeros((niter, T-1))\n",
    "for t in range(T-1):\n",
    "    V[:,t] = V0\n",
    "episode_rewards = np.zeros(niter)\n",
    "for i in range(niter):\n",
    "    print('Episode %d begins' %i)\n",
    "    total_reward = 0 \n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        rho_0_s, rho_s = get_bar_pas_coefficients(s, N, M, discretize, discretized_N, tau, mu, vaccine_limit)\n",
    "        delta_0_s, delta_s = get_ras_coefficients(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu, vaccine_limit)\n",
    "        ub_a = np.asarray([np.min([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation1(act_dim, num_states, lam, V[:,t+1], k, delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        xs_table[i][t] = s[0]\n",
    "        xi_table[i][t] = s[1]\n",
    "        a1_table[i][t] = a[0]\n",
    "        a2_table[i][t] = a[1]\n",
    "        # update reward\n",
    "        total_reward += get_ras(a, delta_s, delta_0_s)\n",
    "        # sample next state \n",
    "        pas = get_far2_from_bar_pas(a, N, act_dim, rho_0_s, rho_s, discretize, discretized_N)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            s0 = np.int(next_s_idx/(discretized_N + 1))\n",
    "            s1 = next_s_idx % (discretized_N + 1)\n",
    "            xs = s0*discretize_level\n",
    "            xi = s1*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    xs_table[i][T-1] = s[0]\n",
    "    xi_table[i][T-1] = s[1]\n",
    "    print('Reward', total_reward)\n",
    "    episode_rewards[i] = total_reward\n",
    "    print('Episode %d ends' %i)\n",
    "print('Episodes reward', episode_rewards)\n",
    "print('Average reward', np.mean(episode_rewards))\n",
    "print('-std', np.mean(episode_rewards) - 0.5*np.std(episode_rewards))\n",
    "print('+std', np.mean(episode_rewards) + 0.5*np.std(episode_rewards))\n",
    "print('XS: \\n', xs_table)\n",
    "print('XI: \\n', xi_table)\n",
    "print('A1: \\n', a1_table)\n",
    "print('A2: \\n', a2_table)\n",
    "print('Average xs', np.mean(xs_table, axis = 0))\n",
    "print('Average xi', np.mean(xi_table, axis = 0))\n",
    "print('Average a1', np.mean(a1_table, axis = 0))\n",
    "print('Average a2', np.mean(a2_table, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 DRMDP DD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "xs_table = np.zeros((niter, T))\n",
    "xi_table = np.zeros((niter, T))\n",
    "a1_table = np.zeros((niter, T-1))\n",
    "a2_table = np.zeros((niter, T-1))\n",
    "for t in range(T-1):\n",
    "    V[:,t] = V0\n",
    "episode_rewards = np.zeros(niter)\n",
    "for i in range(niter):\n",
    "    print('Episode %d begins' %i)\n",
    "    total_reward = 0 \n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        rho_0_s, rho_s = get_bar_pas_coefficients(s, N, M, discretize, discretized_N, tau, mu, vaccine_limit)\n",
    "        delta_0_s, delta_s = get_ras_coefficients(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu, vaccine_limit)\n",
    "        ub_a = np.asarray([np.min([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation2(act_dim, num_states, lam, V[:,t+1], k, K, delta_s, rho_s, sigma_s, delta_0_s, \n",
    "                                                  rho_0_s, sigma_0_s, bar_Sigma_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        xs_table[i][t] = s[0]\n",
    "        xi_table[i][t] = s[1]\n",
    "        a1_table[i][t] = a[0]\n",
    "        a2_table[i][t] = a[1]\n",
    "        # update reward\n",
    "        total_reward += get_ras(a, delta_s, delta_0_s)\n",
    "        # sample next state \n",
    "        pas = get_far2_from_bar_pas(a, N, act_dim, rho_0_s, rho_s, discretize, discretized_N)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            s0 = np.int(next_s_idx/(discretized_N + 1))\n",
    "            s1 = next_s_idx % (discretized_N + 1)\n",
    "            xs = s0*discretize_level\n",
    "            xi = s1*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    xs_table[i][T-1] = s[0]\n",
    "    xi_table[i][T-1] = s[1]\n",
    "    print('Reward', total_reward)\n",
    "    episode_rewards[i] = total_reward\n",
    "    print('Episode %d ends' %i)\n",
    "print('Episodes reward', episode_rewards)\n",
    "print('Average reward', np.mean(episode_rewards))\n",
    "print('-std', np.mean(episode_rewards) - 0.5*np.std(episode_rewards))\n",
    "print('+std', np.mean(episode_rewards) + 0.5*np.std(episode_rewards))\n",
    "print('XS: \\n', xs_table)\n",
    "print('XI: \\n', xi_table)\n",
    "print('A1: \\n', a1_table)\n",
    "print('A2: \\n', a2_table)\n",
    "print('Average xs', np.mean(xs_table, axis = 0))\n",
    "print('Average xi', np.mean(xi_table, axis = 0))\n",
    "print('Average a1', np.mean(a1_table, axis = 0))\n",
    "print('Average a2', np.mean(a2_table, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
