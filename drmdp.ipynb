{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 MIP Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 DRMDP with decision dependent ambiguity set 2 -- penalty on both mean and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "def solve_bellman_formulation2(act_dim, num_states, lam, next_V, k, K, delta_s, rho_s, sigma_s,\n",
    "                                            delta_0_s, rho_0_s, sigma_0_s, bar_Sigma_s, ub_a):\n",
    "    model1 = gp.Model()\n",
    "    model1.setParam('OutputFlag', False)\n",
    "    a = [0 for i in range(act_dim)]\n",
    "    w = [0 for i in range(num_states)]\n",
    "    u = [0 for i in range(num_states)]\n",
    "    Q = [[0 for j in range(num_states)] for i in range(num_states)]\n",
    "    h = [0 for i in range(num_states)]\n",
    "    m0 = [[0 for j in range(num_states)] for i in range(act_dim)]\n",
    "    m1 = [[0 for j in range(num_states)] for i in range(act_dim)]\n",
    "    m2 = [[[0 for j_ in range(num_states)] for j in range(num_states)] for i in range(act_dim)]\n",
    "    m3 = [[[[0 for j_ in  range(num_states)] for j in range(num_states)] for i_ in range(act_dim)] for i in range(act_dim)]\n",
    "    m4 = [[0 for j in range(num_states)] for i in range(num_states)]\n",
    "    m5 = [[0 for j in range(num_states)] for i in range(num_states)]\n",
    "\n",
    "\n",
    "    r = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'r')\n",
    "    q = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'q')\n",
    "    for i in range(act_dim):\n",
    "        a[i] = model1.addVar(vtype=GRB.INTEGER, lb = 0.0, ub = ub_a[i], name = 'a%d' %i)\n",
    "    for i in range(num_states):\n",
    "        w[i] = model1.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'w%d' %i)\n",
    "    for i in range(num_states):\n",
    "        u[i] = model1.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'u%d' %i)\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            Q[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -np.sqrt(K[i][i]*K[j][j]), ub = np.sqrt(K[i][i]*K[j][j]), name = 'Q%d%d' %(i,j))\n",
    "    for i in range(num_states):\n",
    "        h[i] = model1.addVar(vtype=GRB.CONTINUOUS, name = 'h%d' %i)\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            m0[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm0-%d%d' %(i,j))\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            m1[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm1-%d%d' %(i,j))\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            for j_ in range(num_states):\n",
    "                m2[i][j][j_] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm2-%d%d%d' %(i,j,j_))\n",
    "    for i in range(act_dim):\n",
    "        for i_ in range(act_dim):\n",
    "            for j in range(num_states):\n",
    "                for j_ in range(num_states):\n",
    "                    m3[i][i_][j][j_] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm3-%d%d%d%d' %(i,i_,j,j_))\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            m4[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm4-%d%d' %(i,j))\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            m5[i][j] = model1.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm5-%d%d' %(i,j))\n",
    "    \n",
    "    # Objective\n",
    "    obj = 1*r + delta_0_s\n",
    "    for i in range(act_dim):\n",
    "        obj.addTerms(delta_s[i], a[i])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(-rho_0_s[j], w[j])\n",
    "    for j in range(num_states):\n",
    "        for i in range(act_dim):\n",
    "            obj.addTerms(-rho_s[i][j], m0[i][j])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(rho_0_s[j], u[j])\n",
    "    for j in range(num_states):\n",
    "        for i in range(act_dim):\n",
    "            obj.addTerms(rho_s[i][j], m1[i][j])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            obj.addTerms(rho_0_s[j]*rho_0_s[j_], Q[j][j_])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            for i in range(act_dim):\n",
    "                obj.addTerms(rho_0_s[j_]*rho_s[i][j] + rho_0_s[j]*rho_s[i][j_], m2[i][j][j_])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            for i in range(act_dim):\n",
    "                for i_ in range(act_dim):\n",
    "                    obj.addTerms(rho_s[i][j]*rho_s[i_][j_], m3[i][i_][j][j_])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            obj.addTerms(-bar_Sigma_s[j][j_]*sigma_0_s, Q[j][j_])\n",
    "    for j in range(num_states):\n",
    "        for j_ in range(num_states):\n",
    "            for i in range(act_dim):\n",
    "                obj.addTerms(-bar_Sigma_s[j][j_]*sigma_s[i], m2[i][j][j_])\n",
    "    model1.setObjective(obj, GRB.MAXIMIZE)\n",
    "\n",
    "    # Constraint 1\n",
    "    constraint1 = q - r\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            constraint1.addTerms(-1,m5[i][j])\n",
    "    model1.addConstr(constraint1, GRB.GREATER_EQUAL, 0, \"c1\")\n",
    "\n",
    "    # Constraint 2 -- j constraints\n",
    "    for j in range(num_states):\n",
    "        constraint = lam*next_V[j] + w[j] - u[j] - q\n",
    "        for i in range(num_states): \n",
    "            constraint.addTerms(1, m4[i][j])\n",
    "        for j_ in range(num_states):\n",
    "            constraint.addTerms(-2*rho_0_s[j_], Q[j][j_])\n",
    "        for j_ in range(num_states):\n",
    "            for i in range(act_dim):\n",
    "                constraint.addTerms(-2*rho_s[i][j_], m2[i][j][j_])\n",
    "        model1.addConstr(constraint, GRB.GREATER_EQUAL, 0, \"c2-%d\" %j);\n",
    "\n",
    "    # PSD\n",
    "    for i in range(num_states):\n",
    "        model1.addConstr(Q[i][i] >= gp.quicksum(Q[i][j] for j in range(num_states)), 'PSD diagonal dominance')\n",
    "        model1.addConstr(Q[i][i] >= 0, \"PSD positive diagonal\")\n",
    "        \n",
    "    # McCormick envelopes\n",
    "    # M0\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            model1.addConstr(m0[i][j] - 0*w[j] - a[i]*0 + 0*0 >= 0, \"m0-1-%d%d\" %(i,j))\n",
    "            model1.addConstr(m0[i][j] - ub_a[i]*w[j] - a[i]*k[j] + ub_a[i]*k[j] >= 0, \"m0-2-%d%d\" %(i,j))\n",
    "            model1.addConstr(m0[i][j] - ub_a[i]*w[j] - a[i]*0 + ub_a[i]*0 <= 0, \"m0-3-%d%d\" %(i,j))\n",
    "            model1.addConstr(m0[i][j] - a[i]*k[j] - 0*w[j] + 0*k[j] <= 0, \"m0-4-%d%d\" %(i,j))\n",
    "    \n",
    "    # M1\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            model1.addConstr(m1[i][j] - 0*u[j] - a[i]*0 + 0*0 >= 0, \"m1-1-%d%d\" %(i,j))\n",
    "            model1.addConstr(m1[i][j] - ub_a[i]*u[j] - a[i]*k[j] + ub_a[i]*k[j] >= 0, \"m1-2-%d%d\" %(i,j))\n",
    "            model1.addConstr(m1[i][j] - ub_a[i]*u[j] - a[i]*0 + ub_a[i]*0 <= 0, \"m1-3-%d%d\" %(i,j))\n",
    "            model1.addConstr(m1[i][j] - a[i]*k[j] - 0*u[j] + 0*k[j] <= 0, \"m1-4-%d%d\" %(i,j))\n",
    "    # M2\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            for j_ in range(num_states):\n",
    "                model1.addConstr(m2[i][j][j_] - 0*Q[j][j_] - a[i]*(-np.sqrt(K[j][j]*K[j_][j_])) + 0*(-np.sqrt(K[j][j]*K[j_][j_])) >= 0, \"m2-1-%d%d%d\" %(i,j,j_))\n",
    "                model1.addConstr(m2[i][j][j_] - ub_a[i]*Q[j][j_] - a[i]*np.sqrt(K[j][j]*K[j_][j_]) + ub_a[i]*np.sqrt(K[j][j]*K[j_][j_]) >= 0, \"m2-2-%d%d%d\" %(i,j,j_))\n",
    "                model1.addConstr(m2[i][j][j_] - ub_a[i]*Q[j][j_] - a[i]*(-np.sqrt(K[j][j]*K[j_][j_])) + ub_a[i]*(-np.sqrt(K[j][j]*K[j_][j_])) <= 0, \"m2-3-%d%d%d\" %(i,j,j_))\n",
    "                model1.addConstr(m2[i][j][j_] - a[i]*np.sqrt(K[j][j]*K[j_][j_]) - 0*Q[j][j_] + 0*np.sqrt(K[j][j]*K[j_][j_]) <= 0, \"m2-4-%d%d%d\" %(i,j,j_))\n",
    "\n",
    "    # ub-m2 -- ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])\n",
    "    # lb-m2 -- -ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])\n",
    "\n",
    "    # M3\n",
    "    for i in range(act_dim):\n",
    "        for i_ in range(act_dim):\n",
    "            for j in range(num_states):\n",
    "                for j_ in range(num_states):\n",
    "                    model1.addConstr(m3[i][i_][j][j_] - 0*m2[i][j][j_] - a[i_]*(-ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) + 0*(-ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) >= 0)\n",
    "                    model1.addConstr(m3[i][i_][j][j_] - ub_a[i_]*m2[i][j][j_] - a[i_]*(ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) + ub_a[i_]*(ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) >= 0)\n",
    "                    model1.addConstr(m3[i][i_][j][j_] - ub_a[i_]*m2[i][j][j_] - a[i_]*(-ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) + ub_a[i_]*(-ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) <= 0)\n",
    "                    model1.addConstr(m3[i][i_][j][j_] - a[i_]*(ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) - 0*m2[i][j][j_] + 0*(ub_a[i]*np.sqrt(K[j][j]*K[j_][j_])) <= 0)\n",
    "\n",
    "\n",
    "    for i in range(num_states):\n",
    "        for j in range(num_states):\n",
    "            model1.addConstr(m4[i][j] <= 1)\n",
    "            model1.addConstr(m4[i][j] >= -1)\n",
    "            model1.addConstr(m5[i][j] <= 1)\n",
    "            model1.addConstr(m5[i][j] >= -1)\n",
    "        \n",
    "        \n",
    "\n",
    "    result = model1.optimize()\n",
    "    a = []\n",
    "    for v in model1.getVars():\n",
    "        # print('%s %g,' % (v.varName, v.x), end = \" \")\n",
    "        if 'a' in v.varName:\n",
    "            a.append(v.x)\n",
    "    optimal_objective = model1.getObjective().getValue()\n",
    "    optimal_a = np.asarray(a)\n",
    "    return optimal_objective, optimal_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 DRMDP with decision dependent ambiguity set 1 -- penalty on mean deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "def solve_bellman_formulation1(act_dim, num_states, lam, next_V, k, delta_s, rho_s, delta_0_s, rho_0_s, ub_a):\n",
    "    model2 = gp.Model()\n",
    "    model2.setParam('OutputFlag', False)\n",
    "    a = [0 for i in range(act_dim)]\n",
    "    w = [0 for i in range(num_states)]\n",
    "    u = [0 for i in range(num_states)]\n",
    "    m0 = [[0 for j in range(num_states)] for i in range(act_dim)]\n",
    "    m1 = [[0 for j in range(num_states)] for i in range(act_dim)]\n",
    "    r = model2.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'r')\n",
    "    q = model2.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'q')\n",
    "    for i in range(act_dim):\n",
    "        a[i] = model2.addVar(vtype=GRB.INTEGER, lb = 0.0, ub = ub_a[i], name = 'a%d' %i)\n",
    "    for i in range(num_states):\n",
    "        w[i] = model2.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'w%d' %i)\n",
    "    for i in range(num_states):\n",
    "        u[i] = model2.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'u%d' %i)\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            m0[i][j] = model2.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm0-%d%d' %(i,j))\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "                m1[i][j] = model2.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'm1-%d%d' %(i,j))\n",
    "\n",
    "    # Objective\n",
    "    obj = 1*r + delta_0_s\n",
    "    for i in range(act_dim):\n",
    "        obj.addTerms(delta_s[i], a[i])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(-rho_0_s[j], w[j])\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            obj.addTerms(-rho_s[i][j], m0[i][j])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(rho_0_s[j], u[j])\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            obj.addTerms(rho_s[i][j], m1[i][j])\n",
    "    model2.setObjective(obj, GRB.MAXIMIZE)   \n",
    "\n",
    "    # Constraint 1\n",
    "    model2.addConstr(q-r, GRB.GREATER_EQUAL, 0, \"c1\");\n",
    "\n",
    "    # Constraint 2\n",
    "    for j in range(num_states):\n",
    "        model2.addConstr(lam*next_V[j] + w[j] - u[j] - q >= 0)\n",
    "    \n",
    "    # McCormick envelopes\n",
    "    # M0\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            model2.addConstr(m0[i][j] - 0*w[j] - a[i]*0 + 0*0 >= 0, \"m0-1-%d%d\" %(i,j))\n",
    "            model2.addConstr(m0[i][j] - ub_a[i]*w[j] - a[i]*k[j] + ub_a[i]*k[j] >= 0, \"m0-2-%d%d\" %(i,j))\n",
    "            model2.addConstr(m0[i][j] - ub_a[i]*w[j] - a[i]*0 + ub_a[i]*0 <= 0, \"m0-3-%d%d\" %(i,j))\n",
    "            model2.addConstr(m0[i][j] - a[i]*k[j] - 0*w[j] + 0*k[j] <= 0, \"m0-4-%d%d\" %(i,j))\n",
    "    \n",
    "    # M1\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            model2.addConstr(m1[i][j] - 0*u[j] - a[i]*0 + 0*0 >= 0, \"m1-1-%d%d\" %(i,j))\n",
    "            model2.addConstr(m1[i][j] - ub_a[i]*u[j] - a[i]*k[j] + ub_a[i]*k[j] >= 0, \"m1-2-%d%d\" %(i,j))\n",
    "            model2.addConstr(m1[i][j] - ub_a[i]*u[j] - a[i]*0 + ub_a[i]*0 <= 0, \"m1-3-%d%d\" %(i,j))\n",
    "            model2.addConstr(m1[i][j] - a[i]*k[j] - 0*u[j] + 0*k[j] <= 0, \"m1-4-%d%d\" %(i,j))\n",
    "\n",
    "    result = model2.optimize()\n",
    "    a = []\n",
    "    for v in model2.getVars():\n",
    "        # print('%s %g,' % (v.varName, v.x), end = \" \")\n",
    "        if 'a' in v.varName:\n",
    "            a.append(v.x)\n",
    "    optimal_objective = model2.getObjective().getValue()\n",
    "    optimal_a = np.asarray(a)\n",
    "    return optimal_objective, optimal_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Regular MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "def solve_bellman_formulation3(act_dim, num_states, lam, next_V, delta_s, rho_s, delta_0_s, rho_0_s, ub_a):\n",
    "    model3 = gp.Model()\n",
    "    model3.setParam('OutputFlag', False)\n",
    "    a = [0 for i in range(act_dim)]\n",
    "    for i in range(act_dim):\n",
    "        a[i] = model3.addVar(vtype=GRB.INTEGER, lb = 0.0, ub = ub_a[i], name = 'a%d' %i)\n",
    "    # Objective\n",
    "    obj = delta_0_s + gp.quicksum(delta_s[i]*a[i] for i in range(act_dim))\n",
    "    for j in range(num_states):\n",
    "        obj += lam*rho_0_s[j]*next_V[j]\n",
    "    for i in range(act_dim):\n",
    "        for j in range(num_states):\n",
    "            obj.addTerms(lam*rho_s[i][j]*next_V[j], a[i])\n",
    "    model3.setObjective(obj, GRB.MAXIMIZE)\n",
    "    \n",
    "    result = model3.optimize()\n",
    "    a = []\n",
    "    for v in model3.getVars():\n",
    "        # print('%s %g,' % (v.varName, v.x), end = \" \")\n",
    "        if 'a' in v.varName:\n",
    "            a.append(v.x)\n",
    "    optimal_objective = model3.getObjective().getValue()\n",
    "    optimal_a = np.asarray(a)\n",
    "    return optimal_objective, optimal_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Reguar DRMDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "def solve_bellman_formulation4(act_dim, num_states, lam, next_V, k, delta_s, ps, delta_0_s, ub_a):\n",
    "    model4 = gp.Model()\n",
    "    model4.setParam('OutputFlag', False)\n",
    "    a = [0 for i in range(act_dim)]\n",
    "    w = [0 for i in range(num_states)]\n",
    "    u = [0 for i in range(num_states)]\n",
    "    r = model4.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'r')\n",
    "    q = model4.addVar(vtype=GRB.CONTINUOUS, lb = -GRB.INFINITY, ub = GRB.INFINITY, name = 'q')\n",
    "    for i in range(act_dim):\n",
    "        a[i] = model4.addVar(vtype=GRB.INTEGER, lb = 0.0, ub = ub_a[i], name = 'a%d' %i)\n",
    "    for i in range(num_states):\n",
    "        w[i] = model4.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'w%d' %i)\n",
    "    for i in range(num_states):\n",
    "        u[i] = model4.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub = k[i], name = 'u%d' %i)\n",
    "\n",
    "    # Objective\n",
    "    obj = 1*r + delta_0_s\n",
    "    for i in range(act_dim):\n",
    "        obj.addTerms(delta_s[i], a[i])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(-ps[j], w[j])\n",
    "    for j in range(num_states):\n",
    "        obj.addTerms(ps[j], u[j])\n",
    "    model4.setObjective(obj, GRB.MAXIMIZE)   \n",
    "\n",
    "    # Constraint 1\n",
    "    model4.addConstr(q-r, GRB.GREATER_EQUAL, 0, \"c1\");\n",
    "\n",
    "    # Constraint 2\n",
    "    for j in range(num_states):\n",
    "        model4.addConstr(lam*next_V[j] + w[j] - u[j] - q >= 0)\n",
    "\n",
    "    result = model4.optimize()\n",
    "    a = []\n",
    "    for v in model4.getVars():\n",
    "        # print('%s %g,' % (v.varName, v.x), end = \" \")\n",
    "        if 'a' in v.varName:\n",
    "            a.append(v.x)\n",
    "    optimal_objective = model4.getObjective().getValue()\n",
    "    optimal_a = np.asarray(a)\n",
    "    return optimal_objective, optimal_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using license file /Users/kady/gurobi.lic\n",
      "Academic license - for non-commercial use only\n",
      "1069890.0\n",
      "[6. 1.]\n",
      "1472.0\n",
      "[10.  1.]\n",
      "13080.0\n",
      "[10.  1.]\n",
      "141.0\n",
      "[10.  1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# population size\n",
    "N = 10\n",
    "M = 1\n",
    "\n",
    "act_dim = 2\n",
    "num_states = (N+1)**2\n",
    "lam = 0.9\n",
    "next_V = np.ones(num_states)*10\n",
    "\n",
    "\n",
    "# pernalty coefficients\n",
    "k = np.ones(num_states) \n",
    "K = np.ones((num_states, num_states))\n",
    "\n",
    "# LDR coefficients\n",
    "delta_s = np.ones(act_dim)\n",
    "delta_0_s = 1\n",
    "sigma_s = np.ones(act_dim)\n",
    "sigma_0_s = 1\n",
    "rho_s = np.ones((act_dim, num_states))\n",
    "rho_0_s = np.ones(num_states)\n",
    "ps = np.ones(num_states)\n",
    "\n",
    "bar_Sigma_s = np.ones((num_states, num_states))\n",
    "\n",
    "# bound of actions\n",
    "ub_a = np.asarray([N,M])\n",
    "\n",
    "objective, a2 = solve_bellman_formulation2(act_dim, num_states, lam, next_V, k, K, delta_s, rho_s, sigma_s,\n",
    "                                            delta_0_s, rho_0_s, sigma_0_s, bar_Sigma_s, ub_a)\n",
    "print(objective)\n",
    "print(a2)\n",
    "\n",
    "objective, a1 = solve_bellman_formulation1(act_dim, num_states, lam, next_V, k, delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "print(objective)\n",
    "print(a1)\n",
    "\n",
    "objective, a3 = solve_bellman_formulation3(act_dim, num_states, lam, next_V, delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "print(objective)\n",
    "print(a3)\n",
    "\n",
    "objective, a4 = solve_bellman_formulation4(act_dim, num_states, lam, next_V, k, delta_s, ps, delta_0_s, ub_a)\n",
    "print(objective)\n",
    "print(a4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Vaccine Model Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def get_phi(state, action, population_size, trans_reduc_types, tau, mu):\n",
    "    # tau: probability that a susceptible person becomes infected upon contact with an infectious individual \n",
    "    # mu: the rate of contacts (contacts occur according to a homogenous Poisson process, the rate of contacts)\n",
    "    # beta(t): probability that the next interaction of a random susceptible person is with an infectious person\n",
    "    # alpha(t): the fractional reduction in the infection transmission rate\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    yvt = action[0]\n",
    "    yTt = action[1]\n",
    "    beta_t = xit/N\n",
    "    alpha_t = yTt/(M+1)\n",
    "    phi_t = 1 - np.exp(-(1-alpha_t)*mu*beta_t*tau)\n",
    "    return phi_t\n",
    "    \n",
    "\n",
    "def get_estimate_pas(state, action, population_size, trans_reduc_types, discretize, discreted_N, tau, mu):\n",
    "    # given a state, an action, return estimate of P(*|a,s)\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    dicretize_level = np.int(N/discreted_N)\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    yvt = action[0]\n",
    "    yTt = action[1]\n",
    "    phi_t = get_phi(state, action, N, M, tau, mu)\n",
    "    if discretize == False:\n",
    "        pas_matrix = np.zeros((N+1, N+1))\n",
    "        for xs in range(N+1):\n",
    "            for xi in range(N+1):\n",
    "                if xs + xi == xst - yvt:\n",
    "                    pas_matrix[xs][xi] = stats.binom.pmf(xi, xst - yvt, phi_t)\n",
    "        pas = pas_matrix.flatten()\n",
    "    else:\n",
    "        pas_matrix = np.zeros((discreted_N+1, discreted_N+1))\n",
    "        for xs in range(discreted_N+1):\n",
    "            for xi in range(discreted_N+1):\n",
    "                if xs + xi == np.int((xst - yvt)/dicretize_level):\n",
    "                    pas_matrix[xs][xi] = stats.binom.pmf(xi*dicretize_level, xst - yvt, phi_t)\n",
    "        pas = pas_matrix.flatten()\n",
    "        pas = pas/np.sum(pas)\n",
    "    return pas\n",
    "        \n",
    "\n",
    "def get_estimate_reward(state, action, population_size, trans_reduc_types, \n",
    "               cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu):\n",
    "    # given a state, an action, return estimate of r(a,s)\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    yvt = action[0]\n",
    "    yTt = action[1]\n",
    "    phi_t = get_phi(state, action, N, M, tau, mu)\n",
    "    E_it = (xst - yvt)*phi_t\n",
    "    # cost of implementing transmission reducing method \n",
    "    c_T = np.arange(M+1)*cT_multiplier\n",
    "    # policy maker WTP for health  \n",
    "    lam = wtp\n",
    "    c = cost_per_infect\n",
    "    w = qaly_loss_per_infect\n",
    "    p = vaccine_price\n",
    "    r = -lam*w*E_it - c*E_it - c_T[yTt] - p*yvt\n",
    "    return r\n",
    "\n",
    "def get_pas_parameters(state, population_size, trans_reduc_types, discretize = False, discretized_N = 100, tau = 0.8, mu = 1):\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    if discretize == False:\n",
    "        num_states = (N+1)**2\n",
    "    else:\n",
    "        num_states = (discretized_N+1)**2\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    num_actions = (xst+1)*(M+1)\n",
    "    ds_action = np.zeros((num_actions, 2))\n",
    "    ds_pas = np.zeros((num_actions, num_states))\n",
    "    i = 0\n",
    "    for yv in range(xst+1):\n",
    "        for yT in range(M+1):\n",
    "            action = np.asarray([yv, yT])\n",
    "            ds_action[i,:] = action\n",
    "            ds_pas[i,:] = get_estimate_pas(state, action, N, M, discretize, discretized_N, tau, mu)\n",
    "            i += 1\n",
    "    ds_action = np.hstack((np.ones((num_actions,1)), ds_action))\n",
    "    reg = LinearRegression().fit(ds_action, ds_pas)\n",
    "    rho_0_s = reg.coef_[:,0]\n",
    "    rho_s = reg.coef_[:,1:]\n",
    "    return rho_0_s, np.transpose(rho_s)\n",
    "    \n",
    "def get_r_parameters(state, population_size, trans_reduc_types, cT_multiplier = 2, wtp = 1, \n",
    "                     cost_per_infect = 1, qaly_loss_per_infect = 1, vaccine_price = 0.1, tau = 0.8, mu = 1):\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    num_actions = (xst+1)*(M+1)\n",
    "    ds_action = np.zeros((num_actions, 2))\n",
    "    ds_reward = np.zeros((num_actions, 1))\n",
    "    i = 0\n",
    "    for yv in range(xst+1):\n",
    "        for yT in range(M+1):\n",
    "            action = np.asarray([yv, yT])\n",
    "            ds_action[i,:] = action\n",
    "            ds_reward[i,:] = get_estimate_reward(state, action, N, M, cT_multiplier, wtp, \n",
    "                                                cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu)\n",
    "            i += 1\n",
    "    ds_action = np.hstack((np.ones((num_actions,1)), ds_action))\n",
    "    reg = LinearRegression().fit(ds_action, ds_reward)\n",
    "    delta_0_s = reg.coef_[:,0].flatten()[0]\n",
    "    delta_s = reg.coef_[:,1:].flatten()\n",
    "    return delta_0_s, delta_s\n",
    "\n",
    "def get_ps_parameters(state, population_size, trans_reduc_types, discretize = False, discretized_N = 100, tau = 0.8, mu = 1):\n",
    "    N = population_size\n",
    "    M = trans_reduc_types\n",
    "    if discretize == False:\n",
    "        num_states = (N+1)**2\n",
    "    else:\n",
    "        num_states = (discretized_N+1)**2\n",
    "    xst = state[0]\n",
    "    xit = state[1]\n",
    "    num_actions = (xst+1)*(M+1)\n",
    "    ds_pas = np.zeros((num_actions, num_states))\n",
    "    i = 0\n",
    "    for yv in range(xst+1):\n",
    "        for yT in range(M+1):\n",
    "            action = np.asarray([yv, yT])\n",
    "            ds_pas[i,:] = get_estimate_pas(state, action, N, M, discretize, tau, mu)\n",
    "            i += 1\n",
    "    ds_ps = np.mean(ds_pas, axis = 0)\n",
    "    return ds_ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTDP parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "niter = 2\n",
    "T = 12 # time horizon\n",
    "N = 1000 # population size\n",
    "discretized_N = 100\n",
    "M = 5 # types of transmission-reducing interventions \n",
    "lam = 0.9\n",
    "discretize = True\n",
    "\n",
    "act_dim = 2\n",
    "if discretize == False:\n",
    "    num_states = (N+1)**2\n",
    "else:\n",
    "    discretize_level = np.int(N/discretized_N)\n",
    "    num_states = (discretized_N+1)**2\n",
    "\n",
    "# pernalty coefficients\n",
    "k = np.ones(num_states) \n",
    "K = np.ones((num_states, num_states))\n",
    "\n",
    "\n",
    "# define initial state\n",
    "xs_init = np.int(N*9/10)\n",
    "xi_init = N - xs_init\n",
    "s_init = np.asarray([xs_init, xi_init])\n",
    "\n",
    "# define reward parameters \n",
    "unit = 50000\n",
    "cT_multiplier = N/20 * unit \n",
    "wtp = 1 * unit\n",
    "cost_per_infect = 1 * unit\n",
    "qaly_loss_per_infect = 1 # QALY\n",
    "vaccine_price = 0.5 * unit\n",
    "\n",
    "# define pas paramters \n",
    "tau = 0.5\n",
    "mu = 5\n",
    "\n",
    "vaccine_limit = N/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRMDP with decision dependent ambiguity set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "for i in range(niter):\n",
    "    print('Episode Begins')\n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        rho_0_s, rho_s = get_pas_parameters(s, N, M, discretize, discretized_N, tau, mu)\n",
    "        delta_0_s, delta_s = get_r_parameters(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu)\n",
    "        ub_a = np.asarray([np.amin([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation1(act_dim, num_states, lam, V[:,t+1], k, delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        # display current state and action\n",
    "        print('s', s)\n",
    "        print('a', a)\n",
    "        # sample next state \n",
    "        pas = get_estimate_pas(s, a, N, M, discretize, discretized_N, tau, mu)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            xs = np.int(next_s_idx/(discretized_N + 1))\n",
    "            xi = next_s_idx % (discretized_N + 1)\n",
    "            xs = xs*discretize_level\n",
    "            xi = xi*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    print('Episode Ends')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular DRMDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "for i in range(niter):\n",
    "    print('Episode Begins')\n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        ps = get_ps_parameters(s, N, M, discretize, discretized_N, tau, mu)\n",
    "        delta_0_s, delta_s = get_r_parameters(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu)\n",
    "        ub_a = np.asarray([np.amin([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation4(act_dim, num_states, lam, V[:,t+1], k, delta_s, ps, delta_0_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        # display current state and action\n",
    "        print('s', s)\n",
    "        print('a', a)\n",
    "        # sample next state \n",
    "        pas = get_estimate_pas(s, a, N, M, discretize, discretized_N, tau, mu)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            xs = np.int(next_s_idx/(discretized_N + 1))\n",
    "            xi = next_s_idx % (discretized_N + 1)\n",
    "            xs = xs*discretize_level\n",
    "            xi = xi*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    print('Episode Ends')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "for i in range(niter):\n",
    "    print('Episode Begins')\n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        rho_0_s, rho_s = get_pas_parameters(s, N, M, discretize, discretized_N, tau, mu)\n",
    "        delta_0_s, delta_s = get_r_parameters(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu)\n",
    "        ub_a = np.asarray([np.amin([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation3(act_dim, num_states, lam, V[:,t+1], delta_s, rho_s, delta_0_s, rho_0_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        # display current state and action\n",
    "        print('s', s)\n",
    "        print('a', a)\n",
    "        # sample next state \n",
    "        pas = get_estimate_pas(s, a, N, M, discretize, discretized_N, tau, mu)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            xs = np.int(next_s_idx/(discretized_N + 1))\n",
    "            xi = next_s_idx % (discretized_N + 1)\n",
    "            xs = xs*discretize_level\n",
    "            xi = xi*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    print('Episode Ends')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRMDP with decision-dependent ambiguity set 2 - small scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "niter = 2\n",
    "T = 12 # time horizon\n",
    "N = 200 # population size\n",
    "discretized_N = 9\n",
    "M = 5 # types of transmission-reducing interventions \n",
    "lam = 0.9\n",
    "discretize = True\n",
    "\n",
    "act_dim = 2\n",
    "if discretize == False:\n",
    "    num_states = (N+1)**2\n",
    "else:\n",
    "    discretize_level = np.int(N/discretized_N)\n",
    "    num_states = (discretized_N+1)**2\n",
    "\n",
    "# pernalty coefficients\n",
    "k = np.ones(num_states) \n",
    "K = np.ones((num_states, num_states))\n",
    "\n",
    "\n",
    "# define initial state\n",
    "xs_init = np.int(N*9/10)\n",
    "xi_init = N - xs_init\n",
    "s_init = np.asarray([xs_init, xi_init])\n",
    "\n",
    "# define reward parameters \n",
    "cT_multiplier = N/20\n",
    "wtp = 1\n",
    "cost_per_infect = 1\n",
    "qaly_loss_per_infect = 1\n",
    "vaccine_price = 0.5\n",
    "\n",
    "# define pas paramters \n",
    "tau = 0.5\n",
    "mu = 5\n",
    "\n",
    "vaccine_limit = N/10\n",
    "\n",
    "sigma_s = np.zeros(act_dim)\n",
    "sigma_0_s = 1\n",
    "bar_Sigma_s = np.ones((num_states, num_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.zeros((num_states, T))\n",
    "for i in range(niter):\n",
    "    print('Episode Begins')\n",
    "    s = s_init\n",
    "    for t in range(T-1):\n",
    "        rho_0_s, rho_s = get_pas_parameters(s, N, M, discretize, discretized_N, tau, mu)\n",
    "        delta_0_s, delta_s = get_r_parameters(s, N, M, cT_multiplier, wtp, cost_per_infect, qaly_loss_per_infect, vaccine_price, tau, mu)\n",
    "        ub_a = np.asarray([np.amin([s[0], vaccine_limit]), M])\n",
    "        objective, a = solve_bellman_formulation2(act_dim, num_states, lam, V[:,t+1], k, K, delta_s, rho_s, sigma_s, delta_0_s, \n",
    "                                                  rho_0_s, sigma_0_s, bar_Sigma_s, ub_a)\n",
    "        # update value table\n",
    "        if discretize == False:\n",
    "            current_s_idx = s[0]*(N+1) + s[1]\n",
    "        else:\n",
    "            s0 = np.int(s[0]/discretize_level)\n",
    "            s1 = np.int(s[1]/discretize_level)\n",
    "            current_s_idx = s0*(discretized_N+1) + s1\n",
    "        V[current_s_idx,t] = objective\n",
    "        # display current state and action\n",
    "        print('s', s)\n",
    "        print('a', a)\n",
    "        # sample next state \n",
    "        pas = get_estimate_pas(s, a, N, M, discretize, discretized_N, tau, mu)\n",
    "        next_s_idx = random.choices(np.arange(num_states), pas)[0]\n",
    "        if discretize == False:\n",
    "            xs = np.int(next_s_idx/(N+1))\n",
    "            xi = next_s_idx % (N+1)\n",
    "        else:\n",
    "            xs = np.int(next_s_idx/(discretized_N + 1))\n",
    "            xi = next_s_idx % (discretized_N + 1)\n",
    "            xs = xs*discretize_level\n",
    "            xi = xi*discretize_level\n",
    "        next_s = np.asarray([xs, xi])\n",
    "        s = next_s\n",
    "    print('Episode Ends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
